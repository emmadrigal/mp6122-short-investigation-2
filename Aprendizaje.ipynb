{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Supervisado de un Conjunto de Datos del Clima\n",
    "\n",
    "En este notebook se muestra un benchmark de distintos metodos de aprendizaje supervisado, en este caso es un conjunto de datos climatico en Australia.\n",
    "\n",
    "Este set de datos puede ser descargado del siguiente link:\n",
    "\n",
    "https://www.kaggle.com/jsphyg/weather-dataset-rattle-package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se iniciara por cargar las bibliotecas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "En esta seccion se realiza el pre-procesamiento sobre el conjunto de datos, este proviente de la investigacion anterior y por lo tanto no es explicara el racionamiento de este pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_results = pd.read_csv(\"weatherAUS.csv\")\n",
    "weather_results.replace(to_replace='Yes', value = 1, inplace = True)\n",
    "weather_results.replace(to_replace='No',  value = 0, inplace = True)\n",
    "\n",
    "directions = [\"N\",\"NNE\",\"NE\",\"ENE\",\"E\",\"ESE\", \"SE\", \"SSE\",\"S\",\"SSW\",\"SW\",\"WSW\",\"W\",\"WNW\",\"NW\",\"NNW\"]\n",
    "\n",
    "def compassToDeg(compass_direction):\n",
    "    global directions\n",
    "    index = directions.index(compass_direction)\n",
    "    angle = index * 22.5\n",
    "    return angle\n",
    "\n",
    "def windGustDirConvert(direction):\n",
    "    global directions\n",
    "    if direction['WindGustDir'] in directions:\n",
    "        return compassToDeg(direction['WindGustDir'])\n",
    "\n",
    "def windDir9amConvert(direction):\n",
    "    global directions\n",
    "    if direction['WindDir9am'] in directions:\n",
    "        return compassToDeg(direction['WindDir9am'])\n",
    "\n",
    "def windDir3pmConvert(direction):\n",
    "    global directions\n",
    "    if direction['WindDir3pm'] in directions:\n",
    "        return compassToDeg(direction['WindDir3pm'])\n",
    "\n",
    "windGustDirAngle = weather_results.filter(regex=r'WindGustDir').apply(windGustDirConvert, axis=1)\n",
    "windDir9amAngle = weather_results.filter(regex=r'WindDir9am').apply(windDir9amConvert, axis=1)\n",
    "windDir3pmAngle = weather_results.filter(regex=r'WindDir3pm').apply(windDir3pmConvert, axis=1)\n",
    "\n",
    "windGustDirAngleCos = windGustDirAngle.apply(np.cos)\n",
    "windGustDirAngleSin = windGustDirAngle.apply(np.sin)\n",
    "windDir9amAngleCos = windDir9amAngle.apply(np.cos)\n",
    "windDir9amAngleSin = windDir9amAngle.apply(np.sin)\n",
    "windDir3pmAngleCos = windDir3pmAngle.apply(np.cos)\n",
    "windDir3pmAngleSin = windDir3pmAngle.apply(np.sin)\n",
    "\n",
    "del weather_results['WindGustDir']\n",
    "del weather_results['WindDir9am']\n",
    "del weather_results['WindDir3pm']\n",
    "\n",
    "weather_results['windGustDirAngleCos'] = windGustDirAngleCos\n",
    "weather_results['windGustDirAngleSin'] = windGustDirAngleSin\n",
    "weather_results['windDir9amAngleCos'] = windDir9amAngleCos\n",
    "weather_results['windDir9amAngleSin'] = windDir9amAngleSin\n",
    "weather_results['windDir3pmAngleCos'] = windDir3pmAngleCos\n",
    "weather_results['windDir3pmAngleSin'] = windDir3pmAngleSin\n",
    "\n",
    "weather_results.fillna(weather_results.mean(), inplace = True)\n",
    "\n",
    "weather_results.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalizacion se realizara segun el tipo de dato, es decir toda la temperatura se normalizara segun el maximo global de todos los datos de temperatura, igual para la velocidad del viento y otros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all temperature columns\n",
    "temp_cols = weather_results.filter(regex=r'Temp')\n",
    "temp_cols = ((temp_cols-temp_cols.min())/(temp_cols.max()-temp_cols.min()))\n",
    "\n",
    "weather_results['MinTemp'] = temp_cols['MinTemp']\n",
    "weather_results['MaxTemp'] = temp_cols['MaxTemp']\n",
    "weather_results['Temp9am'] = temp_cols['Temp9am']\n",
    "weather_results['Temp3pm'] = temp_cols['Temp3pm']\n",
    "\n",
    "# Normalize all speed columns\n",
    "speed_cols = weather_results.filter(regex=r'Speed')\n",
    "speed_cols = ((speed_cols-speed_cols.min())/(speed_cols.max()-speed_cols.min()))\n",
    "\n",
    "weather_results['WindGustSpeed'] = speed_cols['WindGustSpeed']\n",
    "weather_results['WindSpeed9am'] = speed_cols['WindSpeed9am']\n",
    "weather_results['WindSpeed3pm'] = speed_cols['WindSpeed3pm']\n",
    "\n",
    "\n",
    "# Normalize all preassure columns\n",
    "preassure_cols = weather_results.filter(regex=r'Pressure')\n",
    "preassure_cols = ((preassure_cols-preassure_cols.min())/(preassure_cols.max()-preassure_cols.min()))\n",
    "\n",
    "\n",
    "weather_results['Pressure9am'] = preassure_cols['Pressure9am']\n",
    "weather_results['Pressure3pm'] = preassure_cols['Pressure3pm']\n",
    "\n",
    "# Normalize all humidity columns\n",
    "humidity_cols = weather_results.filter(regex=r'Humidity')\n",
    "humidity_cols = ((humidity_cols-humidity_cols.min())/(humidity_cols.max()-humidity_cols.min()))\n",
    "\n",
    "weather_results['Humidity9am'] = humidity_cols['Humidity9am']\n",
    "weather_results['Humidity3pm'] = humidity_cols['Humidity3pm']\n",
    "\n",
    "# Normalize all cloud columns\n",
    "cloud_cols = weather_results.filter(regex=r'Cloud')\n",
    "cloud_cols = ((cloud_cols-cloud_cols.min())/(cloud_cols.max()-cloud_cols.min()))\n",
    "\n",
    "weather_results['Cloud9am'] = cloud_cols['Cloud9am']\n",
    "weather_results['Cloud3pm'] = cloud_cols['Cloud3pm']\n",
    "\n",
    "# Normalize remaining columns individually\n",
    "cols_to_norm = ['Rainfall','Evaporation',\n",
    "                'Evaporation','Evaporation',\n",
    "                'Sunshine', 'Cloud9am','Cloud3pm',\n",
    "                'RainToday','RISK_MM', 'RainTomorrow']\n",
    "weather_results[cols_to_norm] = weather_results[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "# Delete non-numerics columns\n",
    "del weather_results['Date']\n",
    "del weather_results['Location']\n",
    "\n",
    "weather_results.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodos Supervisados\n",
    "\n",
    "El set de datos consiste de distintas mediciones de datos meteorologicos ademas de informacion sobre la presencia o no de lluvia en el dia siguiente.\n",
    "\n",
    "Este problema puede ser modelado como un problema de clasificacion donde lo que se busca es clasificar las distinas mediciones segun la existencia o no de lluvia en el dia siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comenzara por dividir el set de datos en sets de entrenamiento y prueba, estos sets se utilizaran para medir el rendimiento de los distintos metodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(weather_results)) < 0.8\n",
    "train = weather_results[msk]\n",
    "test = weather_results[~msk]\n",
    "\n",
    "# Extract the output columns\n",
    "Y_train = train['RainTomorrow']\n",
    "Y_test = test['RainTomorrow']\n",
    "\n",
    "# Extract the output columns\n",
    "del train['RainTomorrow']\n",
    "del test['RainTomorrow']\n",
    "\n",
    "X_train = train\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "El primer metodo en provarse es un metodo de regresion linear. Como lo muestra su nombre este busca aproximaer utilizar por lo que se espera que tenga el rendimiento mas bajo debido a su mayor simplicidad en comparacion de los otros metodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear').fit(X_train, Y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, Y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neigbors\n",
    "\n",
    "Este metodo es llamado en espanhol los `k` vecinos mas cercanos a una \"region\" dada en el espacio para determinar a que clase permanece.\n",
    "\n",
    "El hiperparametro a utilizar en este caso es la cantidad de vecinos `k`, este puede determinarse al obtener multiples cantidades de vecinos para acercarse al valor optimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "''' \n",
    "# El siguiente bloque de codigo se utilizo para\n",
    "# obtener la mejor cantidad de vecinos, para el\n",
    "# notebook solo se ejecuta el caso optimo\n",
    "neighbors_settings = range(20, 45, 5)\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # se construye el modelo de clasificacion\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # se almacena el \"training set accuracy\"\n",
    "    training_accuracy.append(clf.score(X_train, Y_train))\n",
    "    # se almacena la \"generalization accuracy\"\n",
    "    test_accuracy.append(clf.score(X_test, Y_test))\n",
    "\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "'''\n",
    "clf = KNeighborsClassifier(n_neighbors=25)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Training set score: {:.3f}\".format(clf.score(X_train, Y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(clf.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "El naive bayes sigue la formula del teorema de Bayes:\n",
    "\n",
    "$$P(h|d) = \\frac{P(d|h)P(h)}{P(d)}$$\n",
    "\n",
    "En este caso se busca la probabilidad de que llueva dados los parametros de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbg = GaussianNB().fit(X_train, Y_train)\n",
    "print(\"Training set score: {:.3f}\".format(nbg.score(X_train, Y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(nbg.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "Los arboles de decisiones buscan dividir el espacio segun el segun una serie de \"preguntas\" segun ciertos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "El algoritmo de los bosques aleatorios, se encuentra relacionado a los arboles de decisiones. \n",
    "\n",
    "Este create una multitud de arboles de deciciones y estima segun el consenso de todos los arboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# El siguiente bloque de codigo se utilizo para\n",
    "# obtener la mejor cantidad de estimadores, para el\n",
    "# notebook solo se ejecuta el caso optimo\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "estimator_settings = range(1, 10)\n",
    "for n_estimators in estimator_settings:\n",
    "    # se construye el modelo de clasificacion\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # se almacena el \"training set accuracy\"\n",
    "    training_accuracy.append(clf.score(X_train, Y_train))\n",
    "    # se almacena la \"generalization accuracy\"\n",
    "    test_accuracy.append(clf.score(X_test, Y_test))\n",
    "\n",
    "plt.plot(estimator_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(estimator_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.legend()\n",
    "'''\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=5).fit(X_train, Y_train)\n",
    "print(\"Training set score: {:.3f}\".format(rf.score(X_train, Y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(rf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM\n",
    "\n",
    "El nombre de este algoritmo viene de sus siglas en ingles *Support Vector Machine* o maquinas de soporte vectorial en espanhol.\n",
    "\n",
    "Y busca el vector \"optimo\" que divide a dos conjuntos de datos. En el caso de este conjunto al tener mas de 2 dimensiones de entrada se tiene un hyperplano para dividir el conjunto de datos.\n",
    "\n",
    "Por default, como en el codigo que se muestra a continuacion, se utiliza un kernel *RBG* que \"anhade\" dimensiones extra para obtener resultados no lineales.\n",
    "\n",
    "**Cuidado**: Este metodo es lento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(gamma='auto')\n",
    "svc.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svc.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(svc.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "\n",
    "AdaBoost busca crear un clasificador \"fuerte\" basado en una serie de clasificadores mas \"debiles\". Este utiliza como base *stumps* de decision en lugar de utilizar arboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# El siguiente bloque de codigo se utilizo para\n",
    "# obtener la mejor cantidad de estimadores, para el\n",
    "# notebook solo se ejecuta el caso optimo\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "estimator_settings = range(1, 10)\n",
    "for n_estimators in estimator_settings:\n",
    "    # se construye el modelo de clasificacion\n",
    "    clf = AdaBoostClassifier(n_estimators=n_estimators)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # se almacena el \"training set accuracy\"\n",
    "    training_accuracy.append(clf.score(X_train, Y_train))\n",
    "    # se almacena la \"generalization accuracy\"\n",
    "    test_accuracy.append(clf.score(X_test, Y_test))\n",
    "\n",
    "plt.plot(estimator_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(estimator_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.legend()\n",
    "'''\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(clf.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "\n",
    "La idea detrás del *Voting Classifier* es combinar clasificadores conceptualmente diferentes de aprendizaje automático y usar un voto mayoritario o las predicciones promedio (voto suave) para predecir las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)])\n",
    "voting.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(voting.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(voting.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacion de Resultados\n",
    "\n",
    "En la siguiente tabla se resumen los resultados obtenidos. Se tienen dos resultados uno de entrenamiento y otro prueba para poder identificar sobreajuste de existir.\n",
    "\n",
    "\n",
    "| Metodo                     | Entrenamiento  | Prueba     |\n",
    "|----------------------------|----------------|------------|\n",
    "| Linear Regression          |          0.903 |      0.903 |\n",
    "| k-Nearest Neighbors (k=25) |          0.829 |      0.816 |\n",
    "| Naive Bayes                |          0.952 |      0.953 |\n",
    "| Decision Trees             |          1.000 |      1.000 |\n",
    "| Random Forest (n=5)       |          1.000 |      1.000 |\n",
    "| Kernel SVM                 |          0.868 |      0.888 |\n",
    "| AdaBoost (n=1)            |          1.000 |      1.000 |\n",
    "| Voting Classifier          |          0.989 |      0.989 |\n",
    "\n",
    "El metodo con el peor rendimiento es el de kNN, mientras que 3 de los metodos que toman mas de un estimador tienen una precision del 100%.\n",
    "\n",
    "Ademas el regresor linear, el mas sencillo tiene un muy buen rendimiento. Esto probablemente representa que el conjunto de datos en general tiene un comportamiento muy cercano al lineal, por los metodos son capaces de aproximar esta linearidad con ligeras variaciones como los que tienen mas de un estimador tienen un rendimiento muchos mas alto.\n",
    "\n",
    "Debido al alto rendimiento de los clasificadores es posible que se puedan remover muchas de las variables del conjunto de datos y no sacrificar el rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
